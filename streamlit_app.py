import os

os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GRPC_TRACE"] = ""

import asyncio
from pathlib import Path
from typing import Optional
import streamlit as st
import multiprocessing
import uvicorn
import time
import httpx
from PIL import Image
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage


# ==============================================================================
# ë²¡ì—”ë“œ ì„œë²„ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================================================

def run_api_server():
    """uvicornì„ ì‚¬ìš©í•˜ì—¬ FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    from api_server import app
    print("[API Server Process] Starting Uvicorn server...")
    uvicorn.run(app, host="127.0.0.1", port=8000)


def is_server_running():
    """ì„œë²„ê°€ ì‘ë‹µí•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ ì‹¤í–‰ ì—¬ë¶€ë¥¼ íŒë‹¨"""
    try:
        with httpx.Client() as client:
            response = client.get("http://127.0.0.1:8000/docs")
            return response.status_code == 200
    except httpx.ConnectError:
        return False


# ==============================================================================
# ì•± ì „ì²´ì—ì„œ ì‚¬ìš©ë  ìƒìˆ˜ë“¤
# ==============================================================================

system_prompt = (
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì†Œìƒê³µì¸ì„ ìœ„í•œ ìµœê³ ì˜ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
    "ì œê³µëœ ë°ì´í„° ë¶„ì„ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
)

greeting = (
    "ì‚¬ì¥ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” ì‚¬ì¥ë‹˜ì˜ ë§ˆì¼€íŒ… ê³ ë¯¼ì„ í•´ê²°í•´ ë“œë¦´ ë¹„ë°€ìƒë‹´ì†Œì˜ AI ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. "
    "ì„±ê³µì ì¸ ë§ˆì¼€íŒ…ì˜ ì²«ê±¸ìŒ, ë°”ë¡œ ê³ ê°ì„ ì•„ëŠ” ê²ƒì´ì£ . ë¶„ì„í•˜ê³  ì‹¶ì€ ê°€ë§¹ì  ìƒí˜¸ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”."
    "\n(ì˜ˆ: ë™ëŒ€ë¬¸ì—½ê¸°ë–¡ë³¶ì´, ìœ ìœ ì»¤í”¼, í¬ë§ë¶„ì‹ ë“±)"
)


# ==============================================================================
# Streamlit ì•±ì˜ ë©”ì¸ UI ë° ë¡œì§
# ==============================================================================

def main_app():
    """Streamlit ì•±ì˜ ì „ì²´ UIì™€ ë¡œì§ì„ í¬í•¨í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""

    st.set_page_config(page_title="ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ë¹„ë°€ìƒë‹´ì†Œ", layout="wide")

    ASSETS = Path(__file__).parent / "assets"
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")

    @st.cache_data(show_spinner=False)
    def load_image(name: str) -> Optional[Image.Image]:
        p = ASSETS / name
        return Image.open(p) if p.exists() else None

    def clear_chat_history():
        st.session_state.messages = [SystemMessage(content=system_prompt), AIMessage(content=greeting)]
        st.session_state.analysis_complete = False

    with st.sidebar:
        img = load_image("shc_ci_basic_00.png")
        if img:
            st.image(img, use_container_width=True)
        st.markdown("<p style='text-align:center;'>2025 Big Contest</p>", unsafe_allow_html=True)
        st.markdown("<p style='text-align:center;'>AI DATA í™œìš©ë¶„ì•¼</p>", unsafe_allow_html=True)
        st.button("Clear Chat History", on_click=clear_chat_history)

    st.title("ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ğŸ”‘ ë¹„ë°€ìƒë‹´ì†Œ")
    st.subheader("#ìš°ë¦¬ë™ë„¤ #ìˆ¨ì€ë§›ì§‘ #ì†Œìƒê³µì¸ #ë§ˆì¼€íŒ… #ì „ëµ .. ğŸ¤¤")
    hero = load_image("image_gen3.png")
    if hero:
        st.image(hero, use_container_width=True, caption="ğŸŒ€ ë¨¸ë¦¬ì•„í”ˆ ë§ˆì¼€íŒ… ğŸ“Š ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?")
    st.write("")

    if "messages" not in st.session_state:
        clear_chat_history()

    for m in st.session_state.messages:
        if isinstance(m, SystemMessage):
            continue
        role = "user" if isinstance(m, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.markdown(m.content.replace('\n', '  \n'))

    def render_chat_message(role: str, content: str):
        with st.chat_message(role):
            st.markdown(str(content).replace("<br>", "  \n"))

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",  # ëª¨ë¸ëª…ì„ ìµœì‹  ë²„ì „ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1,
    )

    ANALYSIS_SERVER_URL = "http://127.0.0.1:8000/analyze"

    async def process_user_input(user_query: str) -> dict:
        output = {"images": [], "reply": "", "error": ""}
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    ANALYSIS_SERVER_URL, json={"user_query": user_query}, timeout=300.0
                )
                response.raise_for_status()
                analysis_result = response.json()

            if not analysis_result.get("success"):
                output["error"] = analysis_result.get("message", "ë¶„ì„ ì‹¤íŒ¨")
                return output

            assets = analysis_result.get("assets", {})
            if assets.get("age_png"): output["images"].append(assets["age_png"])
            if assets.get("aud_png"): output["images"].append(assets["aud_png"])

            generated_prompt = analysis_result.get("prompt")
            if generated_prompt:
                messages = [
                    SystemMessage(content=system_prompt),
                    HumanMessage(content=generated_prompt)
                ]
                llm_response = await llm.ainvoke(messages)
                output["reply"] = llm_response.content
            else:
                output["error"] = "í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨"

        except httpx.ConnectError:
            output["error"] = "ë¶„ì„ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
        except Exception as e:
            output["error"] = f"ì˜¤ë¥˜ ë°œìƒ: {e!r}"

        return output

    if "analysis_complete" not in st.session_state:
        st.session_state.analysis_complete = False

    query = st.chat_input("ê°€ë§¹ì  ìƒí˜¸ëª…ì„ ì…ë ¥í•˜ê±°ë‚˜ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”...")
    if query:
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  í™”ë©´ì— í‘œì‹œ
        st.session_state.messages.append(HumanMessage(content=query))
        with st.chat_message("user"):
            st.markdown(query)

        # 1. ì²« ë¶„ì„ ìš”ì²­ì¸ ê²½ìš° (ê°€ë§¹ì ëª… ì…ë ¥)
        if not st.session_state.analysis_complete:
            with st.spinner("ì‚¬ì¥ë‹˜ì˜ ê°€ê²Œë¥¼ ë¶„ì„í•˜ê³  ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                result_data = asyncio.run(process_user_input(query))
                with st.chat_message("assistant"):
                    if result_data.get("error"):
                        error_msg = result_data["error"]
                        st.error(error_msg)
                        st.session_state.messages.append(AIMessage(content=error_msg))
                    else:
                        reply_text = result_data.get("reply", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        image_paths = result_data.get("images", [])

                        # --- ì´ë¯¸ì§€ ë¶„ë¦¬ ë¡œì§ ---
                        split_keyword_base = "ìš°ë¦¬ ê°€ê²Œ í˜„í™© ìš”ì•½"
                        found_split = False
                        for keyword_variant in [
                            f"### {split_keyword_base}", f"**{split_keyword_base}**", f"{split_keyword_base}", split_keyword_base
                        ]:
                            if keyword_variant in reply_text:
                                parts = reply_text.split(keyword_variant, 1)
                                st.markdown((parts[0] + keyword_variant).replace('\n', '  \n'))
                                if image_paths:
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        if len(image_paths) > 0 and Path(image_paths[0]).exists():
                                            st.image(image_paths[0], use_container_width=True, caption="ì—°ë ¹ ë¯¹ìŠ¤")
                                    with col2:
                                        if len(image_paths) > 1 and Path(image_paths[1]).exists():
                                            st.image(image_paths[1], use_container_width=True, caption="ì˜¤ë””ì–¸ìŠ¤ ì‹ í˜¸")
                                st.markdown(parts[1].replace('\n', '  \n'))
                                found_split = True
                                break

                        if not found_split:
                            st.markdown(reply_text)
                            if image_paths:
                                col1, col2 = st.columns(2)
                                with col1:
                                    if len(image_paths) > 0 and Path(image_paths[0]).exists():
                                        st.image(image_paths[0], use_container_width=True, caption="ì—°ë ¹ ë¯¹ìŠ¤")
                                with col2:
                                    if len(image_paths) > 1 and Path(image_paths[1]).exists():
                                        st.image(image_paths[1], use_container_width=True, caption="ì˜¤ë””ì–¸ìŠ¤ ì‹ í˜¸")

                        st.session_state.messages.append(AIMessage(content=reply_text))
                        st.session_state.analysis_complete = True

        # 2. ë¶„ì„ ì™„ë£Œ í›„ì˜ í›„ì† ì§ˆë¬¸ì¸ ê²½ìš°
        else:
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                llm_response = llm.invoke(st.session_state.messages)
                reply_text = llm_response.content

                with st.chat_message("assistant"):
                    st.markdown(reply_text.replace('\n', '  \n'))
                st.session_state.messages.append(AIMessage(content=reply_text))


# ==============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ==============================================================================

if __name__ == '__main__':
    # ë©€í‹°í”„ë¡œì„¸ì‹± ê´€ë ¨ ì„¤ì • (Windows ì‚¬ìš©ìë¥¼ ìœ„í•´ í•„ìš”)
    multiprocessing.freeze_support()

    if not is_server_running():
        print("[Main] API server is not running. Starting it now...")
        server_process = multiprocessing.Process(target=run_api_server, daemon=True)
        server_process.start()
        time.sleep(5)
        if is_server_running():
            print("[Main] API server has started successfully.")
        else:
            print("[Main] Error: API server failed to start.")
            st.error("ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•±ì„ ë‹¤ì‹œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()
    else:
        print("[Main] API server is already running.")

    main_app()