import os

os.environ["GRPC_VERBOSITY"] = "ERROR"
os.environ["GRPC_TRACE"] = ""

import sys
import asyncio
from pathlib import Path
from typing import Optional
import streamlit as st
import multiprocessing
import uvicorn
import time
import httpx
from PIL import Image
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage


# ==============================================================================
# ë²¡ì—”ë“œ ì„œë²„ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# ==============================================================================

def run_api_server():
    """uvicornì„ ì‚¬ìš©í•˜ì—¬ FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    from api_server import app
    print("[API Server Process] Starting Uvicorn server...")
    uvicorn.run(app, host="127.0.0.1", port=8000)


def is_server_running():
    """ì„œë²„ê°€ ì‘ë‹µí•˜ëŠ”ì§€ í™•ì¸í•˜ì—¬ ì‹¤í–‰ ì—¬ë¶€ë¥¼ íŒë‹¨"""
    try:
        with httpx.Client() as client:
            response = client.get("http://127.0.0.1:8000/docs")
            return response.status_code == 200
    except httpx.ConnectError:
        return False


# ==============================================================================
# ì•± ì „ì²´ì—ì„œ ì‚¬ìš©ë  ìƒìˆ˜ë“¤
# ==============================================================================

# ë°±ì—”ë“œê°€ ëª¨ë“  ì§€ì‹œë¥¼ í•˜ë¯€ë¡œ ë‹¨ìˆœí•œ ì—­í• ë§Œ ë¶€ì—¬
system_prompt = (
    "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì†Œìƒê³µì¸ì„ ìœ„í•œ ìµœê³ ì˜ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
    "ì œê³µëœ ë°ì´í„° ë¶„ì„ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."
)

greeting = (
    "ì‚¬ì¥ë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” ì‚¬ì¥ë‹˜ì˜ ë§ˆì¼€íŒ… ê³ ë¯¼ì„ í•´ê²°í•´ ë“œë¦´ ë¹„ë°€ìƒë‹´ì†Œì˜ AI ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. "
    "ì„±ê³µì ì¸ ë§ˆì¼€íŒ…ì˜ ì²«ê±¸ìŒ, ë°”ë¡œ ê³ ê°ì„ ì•„ëŠ” ê²ƒì´ì£ . ë¶„ì„í•˜ê³  ì‹¶ì€ ê°€ë§¹ì  ìƒí˜¸ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”."
    "\n(ì˜ˆ: ë™ëŒ€ë¬¸ì—½ê¸°ë–¡ë³¶ì´, ìœ ìœ ì»¤í”¼, í¬ë§ë¶„ì‹ ë“±)"
)


# ==============================================================================
# Streamlit ì•±ì˜ ë©”ì¸ UI ë° ë¡œì§
# ==============================================================================

def main_app():
    """Streamlit ì•±ì˜ ì „ì²´ UIì™€ ë¡œì§ì„ í¬í•¨í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""

    st.set_page_config(page_title="ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ë¹„ë°€ìƒë‹´ì†Œ", layout="wide")

    ASSETS = Path(__file__).parent / "assets"
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")

    @st.cache_data(show_spinner=False)
    def load_image(name: str) -> Optional[Image.Image]:
        p = ASSETS / name
        return Image.open(p) if p.exists() else None

    def clear_chat_history():
        st.session_state.messages = [SystemMessage(content=system_prompt), AIMessage(content=greeting)]

    with st.sidebar:
        img = load_image("shc_ci_basic_00.png")
        if img:
            st.image(img, use_container_width=True)
        st.markdown("<p style='text-align:center;'>2025 Big Contest</p>", unsafe_allow_html=True)
        st.markdown("<p style='text-align:center;'>AI DATA í™œìš©ë¶„ì•¼</p>", unsafe_allow_html=True)
        st.button("Clear Chat History", on_click=clear_chat_history)

    st.title("ì‹ í•œì¹´ë“œ ì†Œìƒê³µì¸ ğŸ”‘ ë¹„ë°€ìƒë‹´ì†Œ")
    st.subheader("#ìš°ë¦¬ë™ë„¤ #ìˆ¨ì€ë§›ì§‘ #ì†Œìƒê³µì¸ #ë§ˆì¼€íŒ… #ì „ëµ .. ğŸ¤¤")
    hero = load_image("image_gen3.png")
    if hero:
        st.image(hero, use_container_width=True, caption="ğŸŒ€ ë¨¸ë¦¬ì•„í”ˆ ë§ˆì¼€íŒ… ğŸ“Š ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ê¹Œ?")
    st.write("")

    if "messages" not in st.session_state:
        clear_chat_history()

    for m in st.session_state.messages:
        if isinstance(m, SystemMessage):
            continue
        role = "user" if isinstance(m, HumanMessage) else "assistant"
        with st.chat_message(role):
            st.write(m.content)

    def render_chat_message(role: str, content: str):
        with st.chat_message(role):
            st.markdown(str(content).replace("<br>", "  \n"))

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.1,
    )

    ANALYSIS_SERVER_URL = "http://127.0.0.1:8000/analyze"

    async def process_user_input(user_query: str) -> dict:
        output = {"images": [], "reply": "", "error": ""}
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    ANALYSIS_SERVER_URL, json={"user_query": user_query}, timeout=300.0
                )
                response.raise_for_status()
                analysis_result = response.json()

            if not analysis_result.get("success"):
                output["error"] = analysis_result.get("message", "ë¶„ì„ ì‹¤íŒ¨")
                return output

            assets = analysis_result.get("assets", {})
            if assets.get("age_png"): output["images"].append(assets["age_png"])
            if assets.get("aud_png"): output["images"].append(assets["aud_png"])

            generated_prompt = analysis_result.get("prompt")
            if generated_prompt:
                messages = [HumanMessage(content=generated_prompt)]
                llm_response = await llm.ainvoke(messages)
                output["reply"] = llm_response.content
            else:
                output["error"] = "í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨"

        except httpx.ConnectError:
            output["error"] = "ë¶„ì„ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•±ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
        except Exception as e:
            output["error"] = f"ì˜¤ë¥˜ ë°œìƒ: {e!r}"

        return output

    query = st.chat_input("ê°€ë§¹ì  ìƒí˜¸ëª…ì„ ì…ë ¥í•˜ì„¸ìš”...")
    if query:
        st.session_state.messages.append(HumanMessage(content=query))
        render_chat_message("user", query)
        with st.spinner("ì‚¬ì¥ë‹˜ì˜ ê°€ê²Œë¥¼ ë¶„ì„í•˜ê³  ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            result_data = asyncio.run(process_user_input(query))
            with st.chat_message("assistant"):
                if result_data.get("error"):
                    error_msg = result_data["error"]
                    st.error(error_msg)
                    st.session_state.messages.append(AIMessage(content=error_msg))
                else:
                    reply_text = result_data.get("reply", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    image_paths = result_data.get("images", [])

                    split_keyword_base = "ê·¸ë˜í”„ ìš”ì•½"
                    found_split = False
                    for keyword_variant in [
                        f"**{split_keyword_base}:**", f"**{split_keyword_base}**",
                        f"{split_keyword_base}:", split_keyword_base
                    ]:
                        if keyword_variant in reply_text:
                            parts = reply_text.split(keyword_variant, 1)
                            title_and_before = parts[0] + keyword_variant
                            explanation_text = parts[1]
                            found_split = True
                            break

                    if found_split and image_paths:
                        st.markdown(title_and_before)
                        col1, col2 = st.columns(2)
                        with col1:
                            if len(image_paths) > 0 and Path(image_paths[0]).exists():
                                st.image(image_paths[0], use_container_width=True, caption="ì—°ë ¹ ë¯¹ìŠ¤")
                        with col2:
                            if len(image_paths) > 1 and Path(image_paths[1]).exists():
                                st.image(image_paths[1], use_container_width=True, caption="ì˜¤ë””ì–¸ìŠ¤ ì‹ í˜¸")
                        st.markdown(explanation_text)
                    else:
                        st.markdown(reply_text)
                    st.session_state.messages.append(AIMessage(content=reply_text))


# ==============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ==============================================================================

if __name__ == '__main__':
    if not is_server_running():
        print("[Main] API server is not running. Starting it now...")
        server_process = multiprocessing.Process(target=run_api_server, daemon=True)
        server_process.start()
        time.sleep(5)
        if is_server_running():
            print("[Main] API server has started successfully.")
        else:
            print("[Main] Error: API server failed to start.")
            st.error("ë°±ì—”ë“œ ì„œë²„ë¥¼ ì‹œì‘í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•±ì„ ë‹¤ì‹œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()
    else:
        print("[Main] API server is already running.")

    main_app()